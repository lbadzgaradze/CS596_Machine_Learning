{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFKscRKBE_iQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YV-3gS4NFPAb"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy', batch_first = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "train, valid = train.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JUUIHdIeFXYP",
    "outputId": "3b911462-83ef-4c33-a5e2-9307327f67ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n",
      "100%|█████████▉| 399213/400000 [00:22<00:00, 18252.83it/s]"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1eFrzJ8FmaY"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test), \n",
    "    batch_size = 64, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_Nxu4BaFqAb"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, v_size, emb_dim, filter_count, f_size, out_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(v_size, emb_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv1d(in_channels = emb_dim, \n",
    "                                              out_channels = filter_count, \n",
    "                                              kernel_size = fs)\n",
    "                                    for fs in f_size\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(f_size) * filter_count, out_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "            \n",
    "        return self.fc(cat)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "9X8sgbg7Gdzc",
    "outputId": "bcec6520-bfb2-46b3-ddc4-bd3e1c806634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
      "    (1): Conv1d(100, 100, kernel_size=(4,), stride=(1,))\n",
      "    (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_dim = len(TEXT.vocab)\n",
    "emb_dim = 100\n",
    "filter_count = 100\n",
    "f_size = [3,4,5]\n",
    "out_dim = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(in_dim, emb_dim, filter_count, f_size, out_dim, DROPOUT, PAD_IDX)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Rpzr-4CmGy82",
    "outputId": "d7266b7e-0818-4117-874a-624ae41962e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,620,801 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "L7DuTUpuG1bR",
    "outputId": "d298f4ee-d505-4779-e33a-11e44d713e16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5723, -0.8483, -0.0487,  ..., -0.0872, -0.9338,  0.9880],\n",
       "        [-0.5999, -0.8135, -0.4170,  ..., -0.2763, -0.7891, -0.4087],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.5787,  1.5400, -0.3264,  ..., -0.4411,  0.1478, -0.5359],\n",
       "        [-0.0259,  0.2626, -0.4150,  ...,  0.2496,  1.0473, -0.8566],\n",
       "        [-0.5618,  0.5658, -0.2214,  ..., -0.2283,  0.4419,  0.5798]])"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJVj4n5gG4x1"
   },
   "outputs": [],
   "source": [
    "model.embedding.weight.data[TEXT.vocab.stoi[TEXT.unk_token]] = torch.zeros(emb_dim)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a81Z0CGpG9kF"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAcFcdMvG_HR"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(predictions, y):\n",
    "    rounded = torch.round(torch.sigmoid(predictions))\n",
    "    correct = (rounded == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzPwOinUHJw_"
   },
   "outputs": [],
   "source": [
    "def Train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        accuracy = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += accuracy.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyqwQZ_AHNdd"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            accuracy = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += accuracy.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BYaTu5OFHYFc"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "jfW6_6JkHaXv",
    "outputId": "65e8edfe-f767-428b-bd31-1dd0d9344fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.656 | Train Acc: 61.09%\n",
      "\t Val. Loss: 0.521 |  Val. Acc: 77.16%\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.435 | Train Acc: 80.01%\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 85.10%\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.312 | Train Acc: 86.86%\n",
      "\t Val. Loss: 0.339 |  Val. Acc: 85.55%\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.227 | Train Acc: 90.95%\n",
      "\t Val. Loss: 0.312 |  Val. Acc: 86.97%\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.163 | Train Acc: 93.91%\n",
      "\t Val. Loss: 0.325 |  Val. Acc: 87.20%\n"
     ]
    }
   ],
   "source": [
    "global_loss = float('inf')\n",
    "\n",
    "for epoch in range(5):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_accuracy = Train(model, train_iterator, optimizer, criterion)\n",
    "    local_loss, valid_accuracy = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if local_loss < global_loss:\n",
    "        global_loss = local_loss\n",
    "        torch.save(model.state_dict(), 'ForthModel.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_accuracy*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {local_loss:.3f} |  Val. Acc: {valid_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nLm5CwrTH_J_",
    "outputId": "5673e6a7-7a93-4809-835b-8b1cb4f30f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.334 | Test Acc: 85.65%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('ForthModel.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDrlX6mZIGuY"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "def sentiment_prediction(model, sentence, min_len = 5):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaEdWFeUIKKW"
   },
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"AI is terrible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qVkvLgLIPg7"
   },
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"AI is future\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
